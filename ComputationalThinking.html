<!DOCTYPE html>
<html>
<head>
     <link rel="stylesheet" text="text/css" href="myStyle.css">
<title> Ben Wood Portfolio -Iteration</title>
</head>

<body>
<div class="header">
     <h1>Ben Wood E-Portfolio</h1>
</div>

<ul id="NavBar" class="NavHorizontal">
   <li><a class="Home" href="portfolio.html">Home</a></li>
   <li><a class="About Me" href="about.html">About me</a></li>
   <li class="dropdown"><a href="javascript:void(0)" class="dropbutton">Programming</a>
    <div class="dropdown-content">
	<a href="pythonprograms.html">Python Programs</a>
	<a href="androidprograms.html">Android Programs</a>
	<a href="otherprograms.html">Other Programs</a>
	</div>
	</li>
   <li><a class="contact" href="contact.html">Contact Me</a></li>
   <li><a class="active" href="coursecontent.html">Course Content</a></li>
</ul>

<a href="CourseContent.html" class="button">Back</a>

<table>
  <tr>
    <th></th>
    <th>Course Name</th> 
    <th>Units Covered</th>
	<th>Potential Jobs</th>
  </tr>
  <tr>
    <td>Course 1</td>
	<th>Information Technology</th>
    <td>
	<ul id="tableStyle">
	<li>Electrical & Information Engineering</li>
	<li>Engineering Computation</li>
	<li>Energy and the Environment</li>
	</ul></td> 
    <td>50</td>
  </tr>
  <tr>
    <td>Course 2</td>
	<th>Computer Science</th>
    <td>Jackson</td> 
    <td>94</td>
  </tr>
  <tr>
    <td>Course 3</td>
	<th>Cyber Security</th>
    <td>Jackson</td> 
    <td>94</td>
  </tr>
</table>



<p> Computing has been around and commonly used much longer than most people think. The history of computing can stretch all the way from Medieval times up until the modern day, and 
will continue far into the future. <br></p>

<p> In some ways, humans can be considered the very first computers, as the way we process and solve problems if similar to that of modern electronic computers. RAM in a modern 
computer could be compared to the human mind. The way RAM processes information to be passed on and saved to the hard drive is similar to that of how the mind processes information, 
learns what it needs to and passes it onto the subconscious to be saved for later. Peripheral devices such as keyboards and mice can be compared to senses of a human such as touch, 
taste and sight.<br></p>

<p> One of the earliest examples of a device used for computing is the roman and chinese abacus, which would be used as an aid to the brain for solving simple mathematical problems. 
While the earliest form of the abacus is likely to have first appeared around 3000BC, The chinese abacus(suanpan) was invented around 190BC judging by its earliest mentions in chinese 
scriptures. This was a more developed version of chinese counting boards first created around 1000BC. Around 500BC the Romans developed these counting boards slightly to create their 
own variation.<br><p>

<br>

<p>Slightly further into the future, the Antikythera mechanism was created most likely by the Greeks. This ancient device was found off the coast of Greek island Antikythera in 1901, 
and is thought to have been used to predict astronomical positions and eclipses for astrological and calendar related purposes. The device is made up of many different gears used like 
clockwork to predict positions of celestial bodies such as stars and planets.<br><p>

<br>

<p>After these devices, not many more were designed for about 1,500 years. The designs were refined until we find the abacus that we would see today in about 1300AD, but not many new 
devices were invented. This was changed in 1642 when Blaise Pascal invented Pascal’s calculator. This device was revolutionary, and could add, subtract, multiply and divide two 
numbers. This was a huge step up from the then-commonly used abacus, albeit much more complicated and complex. It performed these processes through repeated addition and subtraction.<br><p>

<br>

<p>Later on in the 17th century, in 1694, The Stepped Reckoner was finished. Created by Gottfried Leibniz, this device was a much more mechanically advanced version of Pascal’s 
calculator. It featured 8 dials used to enter the numbers to be used. These dials then turned gears inside the machine, aligning teeth of the gears in different formations for each 
position on the dial. A lever was then cranked to perform the calculation. However, this device was much more unreliable than Pascal’s calculator due to the complexity of the 
machinery inside, allowing a lot more possible problems to arise.<br><p>

<br>

<p>Later on in the early 19th century, computing devices took a huge leap forwards when Charles Babbage, recognised as the ‘father of the computer’ created the difference engines. 
It was an automatic mechanical calculator, and worked by programming a value for each individual column for the machine, and the computer would use the orientation of these columns 
to carry out complex complex mathematical processes at a faster pace for large numbers than ever seen before. This is now commonly recognise as the first computer as we know them 
today.<br><p>

<br>

<p>In 1933, the Telex messaging network came online in the early stage of Germany’s Third Reich. Telex started out as a military exclusive way to send messages, but soon became a 
worldwide network for early forms of commercial text messaging. Telex uses teleprinters, from the 1910s, which were used for Telegraphy, but instead of using dedicated telephone 
lines, Telex connects these teleprinters via voice telephone lines, routed by modified telephone switches. Soon after, this Telex system would become wireless, allowing communication 
across remote regions of the developing world.<br><p>

<br>

<p>In 1937, George Stibitz uses relays for a demonstration, and a proof of concept for applying Boolean logic to the design of computers. Creating one of the first complex 
calculators. This design would be completed in 1939, fully completing the complex calculator, and demonstrating this revolutionary device to the CNC at an American Mathematical 
Society conference, amazing them by remotely running calculations on the CNC in New York City using a teletype terminal. This is likely the first example of remote access computing.<br><p>

<p>In the 20th century, computing blew up, taking leaps and bounds forwards at a time. Computers were used for more purposes than ever before, from communication to military 
purposes. One military use of computing is the enigma machine created by German engineer Arthur Scherbius. The enigma is a cryptographic device created at the end of World War One 
and not intended for, but used in World War Two. It is considered one of the most ingenious mechanical devices ever created, and was far ahead of its time. The enigma machine would 
have settings that must be correctly inputted every day as the codes would change to keep the code secure, and if the correct settings were used, the German messages could be 
decoded. This system beat the best codebreakers the Allied forces could offer until the Turing machine was built.<br><p>

<br>

<p>In 1938, Kondrad Zuse created the Z1 computer, the first freely programmable computer, and used binary floating point numbers and Boolean logic. As revolutionary as this was, the 
device was quite unreliable, and was destroyed during the bombardment of Berlin in December 1943 during World War Two.<br><p>

<p>In 1943 and 1944, a series of computers named colossus were created by British codebreakers in an effort to stop the Axis forces, and were developed by Tommy Flowers. Colossus is 
regarded as the world’s first fully programmable, electronic, digital computer. Although, it was programmed by plugs and switches rather than a stored program. After the war, the 10 
units were destroyed into peices and the blueprints burnt and destroyed to get rid of any evidence to prevent the Germans learning of the existence of the machine so they could not 
use it in the future. Much later in the 20th century, between 1994 and 2006, when computers were infinitely more advanced anyway, working replicas were developed, created and 
rebuilt, and are now on display in the National Museum of Computing.<br><p>

<br>

<p>From 1953 to 1962, the very first mass produced computer was made, the IBM 650. The machine was technically commercially available for purchase for the first time. More than 2000 
of these machines were built. The memory was stored on a rotating magnetic drum. These rotating magnetic drums allowed 1,000, 2,000, or 4,000 words of memory depending on the model. 
The rental cost for this machine including CPU and power supply was $3200/month. This cost equated approximately to a fully loaded Cadillac at the time.<br><p>

<br>

<p>The AMSTRAD CPC 464 is one of the earliest forms of the Home Computer as we know today, and was developed by AMSTRAD, or Alan Sugar. It is considered one of the founders of the 
modern Home Computer, as it was a manageable size, and the price was not as astronomical as seen before for most families at the time at £299. It was also one of the first computers 
to use a monitor and graphical display for the user, especially including colour. The AMSTRAD CPC 464 was released April 12 1984.<br><p>

<br>

<p>Beyond these computers, we get to the computers we see today in modern times, featuring devices such as Personal Computers, and the emergence of portable computers, such as 
mobile phones, laptops, portable games consoles etc. The rate at which new computing devices are being created and innovated is at an all time high, with breakthroughs being made 
faster and faster, leading to a technological golden age.<br><p>

<p>Throughout the history of computing, there have been many influential people that have affected how they have developed, by innovating and creating new and ingenious machines 
all the way from the Abacus to laptops in modern times.<br><p>

<p>Alan Turing is one of these people to have helped make a huge leap forwards in the world of computing. From being a child, Turing was always seen as a type of child prodigy, and 
was gifted particularly mathematically and in the way of problem solving. In 1939, he applied to work at Bletchley Park for the British Army to help code break the German messages. 
In this year, he also conceived his first plans for the Turing machine, the machine that would break the enigma code.<br><p>

<br>

<p>However, this machine would not be built for some time as the machine required considerable financial backing to be built, and Turing had not made much visible work towards 
cracking the enigma code, falling out of favour with the British government. Eventually, Turing was entrusted to crack the code, and the machine was built.<br><p>

<p>The Turing machine could only handle binary codes, and worked by using an infinitely-long string of tape as its memory, and writing 1s and 0s. The machine could then move the 
tape left or right either way once, write 1s or 0s, or erase the number currently there. By doing this, the Turing machine could simulate any computer algorithm, no matter how 
complicated it is. It eventually comes to its conclusion through the use of trial and error. Below is an example of how the tape could look passing through the Turing machine.<br><p>

<br>

<p>Alan Turing is widely considered the father of Artificial Intelligence due to this very primitive form of it, and is credited with coming up with the concept of a stored 
program system, and so is also called the father of Computer Science by some.<br><p>

<p>After the war, the machine was destroyed, along with all paperwork related to the construction and conception of the idea. This was in order to try and hide the machine from the 
Germans incase they used it against British forces in the future. Even the British population did not learn of Turing’s work or his machine until the late 20th century, long after 
Turing’s death. Turing was honoured by the queen for his work during the war when the details of his work were released to the public.<br><p>

<p>Tim Berners-Lee is another man who greatly influenced the course of computing. He is most likely most known for creating the World Wide Web. Although, with the help of 
Robert Cailliau, he also sent the first HTTP communication between client and server, a huge step forward in computer networking.<br><p>

<p>George Boole greatly affected the way we program computers in modern times, by creating the concept of Boolean algebra, where the variables are the values ‘true’ and ‘false’, 
usually denoted as 1 and 0 respectively. He is also credited for conceiving the basis for digital logic and computer science.<br><p>

<p>Dr. Stuart Madnick created the Little Man Computer in 1965, an instructional model of a computer to teach school children, as it models the Von Neumann architecture. It shows 
how a very primitive form of a computer runs by saving and loading information in different ‘mail boxes’.<br><p>

<p>Computers have evolved rapidly recently going from computers that could barely perform simple calculations to running programs and helping us with daily tasks, and becoming 
integral to our daily lives, such as the now common use of smartphones, personal computers, and other devices that are now commonplace in most households.<br><p>


</body>